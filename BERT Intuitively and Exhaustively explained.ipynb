{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "841f685c",
   "metadata": {},
   "source": [
    "# BERT Intuitively and Exhaustively Explained\n",
    "\n",
    "This is a notebook to build and train BERT which follows the tutorial [Link](https://towardsdatascience.com/bert-intuitively-and-exhaustively-explained-48a24ecc1c8a/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0941c5",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "load dataset in streaming mode as it is big dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9416177f-c0c6-4fed-9650-1f1b11b0e816",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc56a1b16d34166b7cb1f3583dde98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('wikimedia/wikipedia', '20231101.en', trust_remote_code=True, streaming=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c303c",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c16aaf-311b-4e9d-a983-edeca867de49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt') # Sentence tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7436bfb-331a-4b06-9872-b91262593ff2",
   "metadata": {},
   "source": [
    "### Breaking wikipedia articles into sentences and paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c217695a-95ea-4c49-afc1-fa0f2de4d6ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Breaking wikipedia articles into sentences and paragraph\n",
    "'''\n",
    "import itertools\n",
    "\n",
    "num_articles = 1000\n",
    "dataset_iter = iter(dataset['train'])\n",
    "# get n articles\n",
    "articles = list(itertools.islice(dataset_iter, num_articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1968c3da-edd2-4b13-b3e0-830ea18a097a",
   "metadata": {},
   "source": [
    "#### Get paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3bacca-0cd6-4a21-a4a8-dd80b224f83f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get paragraphs\n",
    "paragraphs = []\n",
    "for article in articles:\n",
    "    # print(article)\n",
    "    paragraphs.extend(article['text'].splitlines())\n",
    "\n",
    "paragraphs = [p for p in paragraphs if len(p) > 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a7932a-f415-450c-9287-64e927f8a3b7",
   "metadata": {},
   "source": [
    "### Dividing paragraphs into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fa4ba77-b197-4142-9ea0-de65d47300fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dividing paragraphs into sentences\n",
    "divided_paragraphs = []\n",
    "for p in paragraphs:\n",
    "    divided_paragraphs.append(nltk.sent_tokenize(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cac9c49-22be-490c-b69d-9fd503c9009c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation-states, and capitalism.',\n",
       "  'Anarchism advocates for the replacement of the state with stateless societies and voluntary free associations.',\n",
       "  'As a historically left-wing movement, this reading of anarchism is placed on the farthest left of the political spectrum, usually described as the libertarian wing of the socialist movement (libertarian socialism).'],\n",
       " ['Humans have lived in societies without formal hierarchies long before the establishment of states, realms, or empires.',\n",
       "  'With the rise of organised hierarchical bodies, scepticism toward authority also rose.',\n",
       "  'Although traces of anarchist ideas are found all throughout history, modern anarchism emerged from the Enlightenment.',\n",
       "  \"During the latter half of the 19th and the first decades of the 20th century, the anarchist movement flourished in most parts of the world and had a significant role in workers' struggles for emancipation.\",\n",
       "  'Various anarchist schools of thought formed during this period.',\n",
       "  'Anarchists have taken part in several revolutions, most notably in the Paris Commune, the Russian Civil War and the Spanish Civil War, whose end marked the end of the classical era of anarchism.',\n",
       "  'In the last decades of the 20th and into the 21st century, the anarchist movement has been resurgent once more, growing in popularity and influence within anti-capitalist, anti-war and anti-globalisation movements.'],\n",
       " ['Anarchists employ diverse approaches, which may be generally divided into revolutionary and evolutionary strategies; there is significant overlap between the two.',\n",
       "  'Evolutionary methods try to simulate what an anarchist society might be like, but revolutionary tactics, which have historically taken a violent turn, aim to overthrow authority and the state.',\n",
       "  'Many facets of human civilization have been influenced by anarchist theory, critique, and praxis.'],\n",
       " ['The etymological origin of anarchism is from the Ancient Greek anarkhia, meaning \"without a ruler\", composed of the prefix an- (\"without\") and the word arkhos (\"leader\" or \"ruler\").',\n",
       "  'The suffix -ism denotes the ideological current that favours anarchy.',\n",
       "  'Anarchism appears in English from 1642 as anarchisme and anarchy from 1539; early English usages emphasised a sense of disorder.',\n",
       "  'Various factions within the French Revolution labelled their opponents as anarchists, although few such accused shared many views with later anarchists.',\n",
       "  'Many revolutionaries of the 19th century such as William Godwin (1756–1836) and Wilhelm Weitling (1808–1871) would contribute to the anarchist doctrines of the next generation but did not use anarchist or anarchism in describing themselves or their beliefs.'],\n",
       " ['The first political philosopher to call himself an anarchist () was Pierre-Joseph Proudhon (1809–1865), marking the formal birth of anarchism in the mid-19th century.',\n",
       "  'Since the 1890s and beginning in France, libertarianism has often been used as a synonym for anarchism and its use as a synonym is still common outside the United States.',\n",
       "  'Some usages of libertarianism refer to individualistic free-market philosophy only, and free-market anarchism in particular is termed libertarian anarchism.']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only using paragraps with three or more sentences\n",
    "divided_paragraphs = [pls for pls in divided_paragraphs if len(pls) >= 3]\n",
    "divided_paragraphs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ffb6ca-7876-484a-a40f-46ae0e8b2a48",
   "metadata": {},
   "source": [
    "## Prepare dataset of following sentence pairs, and random sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be2a5a38-a56b-4dfd-a920-06ee6e5004b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare dataset of following sentence pairs, and random sentence\n",
    "\n",
    "import random\n",
    "\n",
    "positive_pairs = []\n",
    "negative_pairs = []\n",
    "\n",
    "num_paragraphs = len(divided_paragraphs)\n",
    "\n",
    "for i, paragraph in enumerate(divided_paragraphs):\n",
    "    for j in range(len(paragraph)-1):\n",
    "        positive_pairs.append((paragraph[j], paragraph[j+1]))\n",
    "        rand_par = i\n",
    "        while rand_par == i:\n",
    "            rand_par = random.randint(0, num_paragraphs-1)\n",
    "        rand_sent = random.randint(0, len(divided_paragraphs[rand_par])-1)\n",
    "        negative_pairs.append((paragraph[j], divided_paragraphs[rand_par][rand_sent]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a923ec6f-fd78-4317-ba36-cbe028eff40d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation-states, and capitalism.',\n",
       "  'Anarchism advocates for the replacement of the state with stateless societies and voluntary free associations.'),\n",
       " ('Anarchism advocates for the replacement of the state with stateless societies and voluntary free associations.',\n",
       "  'As a historically left-wing movement, this reading of anarchism is placed on the farthest left of the political spectrum, usually described as the libertarian wing of the socialist movement (libertarian socialism).')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_pairs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0c75be3-cb7e-4020-b18a-eae4fed384bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Anarchism is a political philosophy and movement that is skeptical of all justifications for authority and seeks to abolish the institutions it claims maintain unnecessary coercion and hierarchy, typically including nation-states, and capitalism.',\n",
       "  'Ælfheah was taken prisoner and held captive for seven months.'),\n",
       " ('Anarchism advocates for the replacement of the state with stateless societies and voluntary free associations.',\n",
       "  'There has been a consequential component of Chinese emigration of illegal origin, most notably Fuzhou people from Fujian Province and Wenzhounese from Zhejiang Province in Mainland China, specifically destined to work in Chinese restaurants in New York City, beginning in the 1980s.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_pairs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39deb6ea-c7ee-48ff-85b9-08917f1315d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "935aed27-e6ee-4f02-9f7d-668f1ec6e8c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load tokenizer\n",
    "from transformers.models.bert.tokenization_bert_fast import BertTokenizerFast\n",
    "tokenizer = BertTokenizerFast.from_pretrained('google-bert/bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d69bfd19-5318-4e62-ad6d-75084b08f16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sentence: Here's a weird word: Withoutadoubticus\n",
      "Token IDs: [[101, 2182, 1005, 1055, 1037, 6881, 2773, 1024, 2302, 9365, 12083, 29587, 102]]\n",
      "token values: ['[CLS]', 'here', \"'\", 's', 'a', 'weird', 'word', ':', 'without', '##ado', '##ub', '##ticus', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Trying out tokenizer\n",
    "sentence = \"Here's a weird word: Withoutadoubticus\"\n",
    "print(f\"Original Sentence: {sentence}\")\n",
    "demo_tokens = tokenizer([sentence])\n",
    "print(f\"Token IDs: {demo_tokens['input_ids']}\")\n",
    "tokens = tokenizer.convert_ids_to_tokens(demo_tokens['input_ids'][0])\n",
    "print(f\"token values: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76992592-94c7-4cf0-b360-4c13e09c3778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='google-bert/bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a53a1-6e01-43cc-9f3f-8d7d712f3ddf",
   "metadata": {},
   "source": [
    "## Define Training Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "643a3217-0364-46ee-8382-02f7a8b968aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd3ac9a5-5964-41c4-8a1e-dad5718998db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# defining the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# number of examples in the batch\n",
    "batch_size = 128 #should be divisible by 2\n",
    "max_input_length = 64 # sequence lenght of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2546416a-2dff-4b39-bb7f-26c8649ebb26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8252a0e-4c53-4db0-9657-9915c1bda66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(batch_index):\n",
    "    # bounds of the batch\n",
    "    start_index = batch_index * batch_size\n",
    "    end_index = start_index + batch_size\n",
    "    \n",
    "    if end_index > len(positive_pairs):\n",
    "        return None, None, None\n",
    "    \n",
    "    # Get the sentence pairs of the batch and their labels\n",
    "    sentence_pairs = []\n",
    "    is_positives = []\n",
    "    \n",
    "    # Creating positive pairs\n",
    "    sentence_pairs.extend(positive_pairs[start_index:start_index + int(batch_size/2)])\n",
    "    is_positives.extend([1] * int(batch_size/2))\n",
    "    \n",
    "    sentence_pairs.extend(negative_pairs[start_index:start_index + int(batch_size/2)])\n",
    "    is_positives.extend([0] * int(batch_size/2))\n",
    "    \n",
    "    # Defining the output\n",
    "    # In output we need:\n",
    "    # - The tokens for sequence in a batch\n",
    "    # - Positioning encoding: to know which sentence it belongs\n",
    "    # - If the examples in batch are positive or negative\n",
    "    \n",
    "    batch_sentence_location_tokens = []\n",
    "    batch_sequence_tokens = []\n",
    "    \n",
    "    # Tokenizing pairs\n",
    "    for sentence_pair in sentence_pairs:\n",
    "        sentence1 = sentence_pair[0]\n",
    "        sentence2 = sentence_pair[1]\n",
    "        \n",
    "        # Tokenzing both sentences\n",
    "        tokens = tokenizer([sentence1, sentence2])\n",
    "        sentence1_tokens = tokens['input_ids'][0]\n",
    "        sentence2_tokens = tokens['input_ids'][1]\n",
    "        \n",
    "        # Trimming the tokens\n",
    "        if len(sentence1_tokens) + len(sentence2_tokens) > max_input_length:\n",
    "            sentence1_tokens = [101] + sentence1_tokens[-int(max_input_length / 2) + 1:] # 101-> CLS token\n",
    "            sentence2_tokens = sentence2_tokens[:int(max_input_length / 2) - 1] + [102] # 102 -> SEP token\n",
    "            \n",
    "        # creating sentence tokens\n",
    "        sentence_tokens = [0] * len(sentence1_tokens) + [1] * len(sentence2_tokens)\n",
    "\n",
    "        # combining and padding\n",
    "        pad_num = max_input_length - len(sentence_tokens)\n",
    "        sequence_tokens = sentence1_tokens + sentence2_tokens + [0] * pad_num\n",
    "        sentence_location_tokens = sentence_tokens + [1] * pad_num\n",
    "\n",
    "        # Adding to batch\n",
    "        batch_sequence_tokens.append(sequence_tokens)\n",
    "        batch_sentence_location_tokens.append(sentence_location_tokens)\n",
    "            \n",
    "    return torch.tensor(batch_sentence_location_tokens), torch.tensor(batch_sequence_tokens), torch.tensor(is_positives)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c327f3fc-be4c-4062-a9be-cefb945d1efd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|██████████| 744/744 [00:14<00:00, 50.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of batches\n",
    "num_batches = len(positive_pairs) // batch_size\n",
    "\n",
    "# Use pool of workers equal to the number of CPU cores\n",
    "with Pool(processes=cpu_count()) as pool:\n",
    "    results = list(tqdm(pool.imap(process_batch, range(num_batches)), total=num_batches))\n",
    "    \n",
    "# Filter out None results from the process_batch function\n",
    "results = [result for result in results if result[0] is not None]\n",
    "\n",
    "# Unpack results into batches\n",
    "sentence_location_batches, sequence_tokens_batches, is_positive_batches = zip(*results)\n",
    "\n",
    "# Stack tokens into final batches\n",
    "sentence_location_batches = torch.stack(sentence_location_batches).to(device)\n",
    "sequence_tokens_batches = torch.stack(sequence_tokens_batches).to(device)\n",
    "is_positive_batches = torch.stack(is_positive_batches).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45576b80-30c3-4069-b5c2-2d1720086b70",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6085910f-aa26-4c4e-a3fc-5ed151dcece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List vocab for random token masking\n",
    "vocab = tokenizer.get_vocab()\n",
    "valid_token_ids = list(vocab.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f890678e-6404-4cf7-98b2-d8533fc9f4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mask_batch(batch_tokens, clone=True):\n",
    "    if clone:\n",
    "        batch_tokens = torch.clone(batch_tokens)\n",
    "    \n",
    "    replace_percentage = 0.15\n",
    "    \n",
    "    # Special tokens not to be removed\n",
    "    exclude_tokens = {0, 100, 101, 102, 103}\n",
    "    \n",
    "    # Create a mask to identify tokens that are eligible for replacement\n",
    "    eligible_mask = ~torch.isin(batch_tokens, torch.tensor(list(exclude_tokens)))\n",
    "    \n",
    "    # Count the number of eligible tokens\n",
    "    num_eligible_tokens = eligible_mask.sum().item()\n",
    "    \n",
    "    # Calculate the number of tokens to potentially mask\n",
    "    num_tokens_to_mask = int(num_eligible_tokens * replace_percentage)\n",
    "    \n",
    "    # Create a random permutation of eligible token indices\n",
    "    eligible_indices = eligible_mask.nonzero(as_tuple = True)\n",
    "    random_indices = torch.randperm(num_eligible_tokens)[:num_tokens_to_mask]\n",
    "    \n",
    "    # Probability distribution for replacement\n",
    "    replacement_probs = torch.tensor([0.8, 0.1, 0.1]) # [mask, original, random]\n",
    "    replacement_choices = torch.multinomial(replacement_probs, num_tokens_to_mask, replacement = True)\n",
    "    \n",
    "    # Vector to store if token was masked (0: not masked, 1: masked)\n",
    "    masked_indicator = torch.zeros_like(batch_tokens, dtype=torch.int32)\n",
    "    \n",
    "    # Apply replacement on sampled choices\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        row = eligible_indices[0][idx]\n",
    "        col = eligible_indices[1][idx]\n",
    "        \n",
    "        # replacing with [MASK]\n",
    "        if replacement_choices[i] == 0:\n",
    "            batch_tokens[row, col] = 103\n",
    "            masked_indicator[row, col] = 1\n",
    "        # replacing with random token\n",
    "        elif replacement_choices[i] == 1:\n",
    "            batch_tokens[row, col] = random.choice(valid_token_ids)\n",
    "            masked_indicator[row, col] = 1\n",
    "        # not replacing\n",
    "        elif replacement_choices[i] == 2:\n",
    "            masked_indicator[row, col] = 1\n",
    "    return batch_tokens, masked_indicator\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bf555b5-5f8e-4097-897b-b768c2a02645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_tokens, masked_indicator = mask_batch(sequence_tokens_batches[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1afd07eb-7c0d-4e9b-9bce-754d3656fdea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2015,  2005,  ...,     0,     0,     0],\n",
       "        [  101,  9617, 11140,  ...,  1007,  1012,   102],\n",
       "        [  101,  4286,  2031,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,   103, 13193,  ...,     0,     0,     0],\n",
       "        [  101,  2011,  1996,  ...,     0,     0,     0],\n",
       "        [  101,   101,  1996,  ...,  2002,  3062,   102]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14073b78-1a5b-482b-9048-f7e2b3acd97b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d9774-2656-446e-8eed-456897bb9cf7",
   "metadata": {},
   "source": [
    "## Embedding\n",
    "\n",
    "converting these tokens (which are integers) into high dimensional vector (embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29019b56-141e-4da4-9ae5-a75fb57e86c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecb775df-c126-42d6-b9a3-1a8961b92038",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "d_model = 256 # represneting the words with 256 dimension vector\n",
    "n_segments = 2 # there are 2 segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63b9888b-270a-4ad1-9d31-8876b65f0af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model) # token embedding\n",
    "        self.pos_embed = nn.Embedding(max_input_length, d_model) # positional embedding\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model) # segment (token type) embedding\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "    \n",
    "    def forward(self, x, seg):\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long).to(device)\n",
    "        pos = pos.unsqueeze(0).expand_as(x) # seq_len -> (batch_size, seq_len)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5e27e59-f63c-49c4-bc45-b9c1100286c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(\n",
       "  (tok_embed): Embedding(30522, 256)\n",
       "  (pos_embed): Embedding(64, 256)\n",
       "  (seg_embed): Embedding(2, 256)\n",
       "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e = Embedding()\n",
    "e.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af24cbdd-2a48-432e-b712-b0b054a14ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 64, 256])\n",
      "tensor([[[ 3.7084e-01,  6.2293e-01,  4.2563e-01,  ..., -8.1008e-01,\n",
      "          -1.2871e+00, -3.7748e-01],\n",
      "         [-1.8087e+00, -3.9436e-01,  1.6049e+00,  ..., -2.4710e-02,\n",
      "          -3.0526e-01,  1.0582e-02],\n",
      "         [ 1.0827e+00, -1.1021e+00,  1.2605e+00,  ..., -3.0210e-01,\n",
      "          -7.2230e-01,  4.3753e-01],\n",
      "         ...,\n",
      "         [ 7.5792e-01, -3.0871e-02, -4.0939e-01,  ...,  8.1252e-01,\n",
      "          -1.3524e+00, -8.2331e-01],\n",
      "         [ 1.1915e-01,  1.5688e-01,  5.6939e-01,  ...,  1.8274e+00,\n",
      "          -9.2547e-01, -7.9873e-01],\n",
      "         [ 2.7542e-02, -7.2319e-01, -9.3103e-02,  ...,  7.8663e-01,\n",
      "          -4.2692e-01, -1.8711e+00]],\n",
      "\n",
      "        [[ 3.7084e-01,  6.2293e-01,  4.2563e-01,  ..., -8.1008e-01,\n",
      "          -1.2871e+00, -3.7748e-01],\n",
      "         [-8.7655e-01, -4.3041e-02,  1.6590e+00,  ...,  1.2388e-02,\n",
      "           6.7928e-01, -7.4830e-01],\n",
      "         [ 1.5005e+00, -1.2057e+00,  3.8033e-01,  ...,  1.8176e-01,\n",
      "          -8.3607e-01, -7.6114e-01],\n",
      "         ...,\n",
      "         [-3.4241e-01,  4.1618e-01, -7.7563e-01,  ...,  3.0713e-01,\n",
      "          -5.6592e-01, -5.6567e-01],\n",
      "         [-7.3176e-01, -4.1758e-01,  2.1402e+00,  ...,  8.6755e-01,\n",
      "          -1.8018e-01, -1.4205e+00],\n",
      "         [-6.0523e-01, -7.4734e-02,  1.1284e-01,  ..., -3.2569e-01,\n",
      "           1.0898e-01, -1.9870e+00]],\n",
      "\n",
      "        [[ 3.7084e-01,  6.2293e-01,  4.2563e-01,  ..., -8.1008e-01,\n",
      "          -1.2871e+00, -3.7748e-01],\n",
      "         [-1.7981e+00, -3.8791e-01,  1.9252e+00,  ...,  7.0705e-01,\n",
      "          -9.2777e-01, -2.7767e-01],\n",
      "         [ 1.0116e+00,  6.9798e-01,  1.1867e+00,  ..., -4.6015e-02,\n",
      "          -1.1539e+00, -7.3292e-01],\n",
      "         ...,\n",
      "         [ 7.5792e-01, -3.0871e-02, -4.0939e-01,  ...,  8.1252e-01,\n",
      "          -1.3524e+00, -8.2331e-01],\n",
      "         [ 1.1915e-01,  1.5688e-01,  5.6939e-01,  ...,  1.8274e+00,\n",
      "          -9.2547e-01, -7.9873e-01],\n",
      "         [ 2.7542e-02, -7.2319e-01, -9.3103e-02,  ...,  7.8663e-01,\n",
      "          -4.2692e-01, -1.8711e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.7084e-01,  6.2293e-01,  4.2563e-01,  ..., -8.1008e-01,\n",
      "          -1.2871e+00, -3.7748e-01],\n",
      "         [-4.8607e-01, -7.9420e-01,  1.6069e+00,  ...,  4.4378e-01,\n",
      "          -4.7055e-01, -1.2276e+00],\n",
      "         [ 1.5587e-01,  4.7742e-03,  2.4535e+00,  ...,  9.9789e-01,\n",
      "          -1.1017e+00,  1.7114e-01],\n",
      "         ...,\n",
      "         [ 7.5792e-01, -3.0871e-02, -4.0939e-01,  ...,  8.1252e-01,\n",
      "          -1.3524e+00, -8.2331e-01],\n",
      "         [ 1.1915e-01,  1.5688e-01,  5.6939e-01,  ...,  1.8274e+00,\n",
      "          -9.2547e-01, -7.9873e-01],\n",
      "         [ 2.7542e-02, -7.2319e-01, -9.3103e-02,  ...,  7.8663e-01,\n",
      "          -4.2692e-01, -1.8711e+00]],\n",
      "\n",
      "        [[ 3.7084e-01,  6.2293e-01,  4.2563e-01,  ..., -8.1008e-01,\n",
      "          -1.2871e+00, -3.7748e-01],\n",
      "         [-1.2224e+00, -1.8789e-01,  1.0752e+00,  ...,  6.3323e-01,\n",
      "           8.4977e-01,  5.4466e-01],\n",
      "         [ 1.7132e+00, -8.3286e-01,  1.2174e+00,  ..., -5.1470e-01,\n",
      "          -7.5799e-02, -1.9008e-01],\n",
      "         ...,\n",
      "         [ 7.5792e-01, -3.0871e-02, -4.0939e-01,  ...,  8.1252e-01,\n",
      "          -1.3524e+00, -8.2331e-01],\n",
      "         [ 1.1915e-01,  1.5688e-01,  5.6939e-01,  ...,  1.8274e+00,\n",
      "          -9.2547e-01, -7.9873e-01],\n",
      "         [ 2.7542e-02, -7.2319e-01, -9.3103e-02,  ...,  7.8663e-01,\n",
      "          -4.2692e-01, -1.8711e+00]],\n",
      "\n",
      "        [[ 3.7084e-01,  6.2293e-01,  4.2563e-01,  ..., -8.1008e-01,\n",
      "          -1.2871e+00, -3.7748e-01],\n",
      "         [-1.7258e+00,  2.6887e-01,  8.8503e-01,  ...,  1.5617e-01,\n",
      "          -7.9581e-01, -4.1275e-01],\n",
      "         [ 1.7132e+00, -8.3286e-01,  1.2174e+00,  ..., -5.1470e-01,\n",
      "          -7.5799e-02, -1.9008e-01],\n",
      "         ...,\n",
      "         [ 1.1650e+00,  8.0974e-01, -1.4681e+00,  ..., -7.0400e-04,\n",
      "          -9.5158e-01, -1.6040e-01],\n",
      "         [-6.5703e-01,  7.8350e-01,  8.4589e-01,  ...,  1.2080e+00,\n",
      "           9.8050e-02, -1.3819e+00],\n",
      "         [-6.0523e-01, -7.4734e-02,  1.1284e-01,  ..., -3.2569e-01,\n",
      "           1.0898e-01, -1.9870e+00]]], grad_fn=<NativeLayerNormBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dummy_embedding = e(sequence_tokens_batches[0], sentence_location_batches[0])\n",
    "print(dummy_embedding.shape)\n",
    "print(dummy_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03afbf-85f7-4a02-80be-ece266b98c45",
   "metadata": {},
   "source": [
    "## Multi-Headed Self Attention\n",
    "\n",
    "### Single attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac119697-f71f-4e7b-bf53-ae53e3449c55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f06c5b1-3fb7-4ff8-a137-af9badb3bf07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "    \n",
    "    def forward(self, Q, K, V):\n",
    "        # Q, K, V of size (batch x sequence_lenght x dim)\n",
    "        scores = torch.matmul(Q,K.transpose(-1,-2)) / np.sqrt(Q.shape[1])\n",
    "        attn = nn.Softmax(dim=1)(scores)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75ff94ea-493b-4013-ae10-d9ed1a5a1e20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1.2951, 1.3503],\n",
       "          [0.7049, 0.7497]]]),\n",
       " tensor([[[0.6179, 0.6837],\n",
       "          [0.3821, 0.3163]]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "q = torch.tensor([[[1.1, 1.3], [0.9, 0.8]]]).to(device)\n",
    "k = torch.tensor([[[0.9, 1], [0.2, 2.1]]]).to(device)\n",
    "v = torch.tensor([[[1.1, 1.3], [0.9, 0.8]]]).to(device)\n",
    "\n",
    "sample = ScaledDotProductAttention().to(device)\n",
    "sample(q, k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689bece1-11b8-4e2b-b3ac-54f0c3d94b8f",
   "metadata": {},
   "source": [
    "### Understanding the shape transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "899bccad-2097-4fb6-a038-45212c5bef8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7]],\n",
       "\n",
       "        [[ 0, -1, -2, -3],\n",
       "         [-4, -5, -6, -7]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the sample value matrix\n",
    "# [batch_size x sequence_len x (query_key_dims * n_heads)]\n",
    "# in this matrix, [0,1,2,3] represents the values for 2 heads across single word\n",
    "sample_val = torch.tensor([[[0,1,2,3],[4,5,6,7]],[[0,-1,-2,-3],[-4,-5,-6,-7]]])\n",
    "sample_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebe71019-d314-414f-a453-f0bbb84f5282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1],\n",
       "          [ 2,  3]],\n",
       "\n",
       "         [[ 4,  5],\n",
       "          [ 6,  7]]],\n",
       "\n",
       "\n",
       "        [[[ 0, -1],\n",
       "          [-2, -3]],\n",
       "\n",
       "         [[-4, -5],\n",
       "          [-6, -7]]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dividing into two heads\n",
    "# [batch_size x sequence_len x query_key_dim x n_heads]\n",
    "sample_val = sample_val.view(2,2,2,2)\n",
    "sample_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a54fa4af-6632-4b57-8ca4-2af275de978f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1],\n",
       "         [ 2,  3]],\n",
       "\n",
       "        [[ 4,  5],\n",
       "         [ 6,  7]],\n",
       "\n",
       "        [[ 0, -1],\n",
       "         [-2, -3]],\n",
       "\n",
       "        [[-4, -5],\n",
       "         [-6, -7]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving the head dimention next to the batch dimension\n",
    "# [batch_size x n_heads x sequence_len x query_key_dim]\n",
    "sample_val = sample_val.reshape(-1, 2, 2)\n",
    "sample_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90728dbc-1b62-42db-9bc2-6956f1dd4c72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  1],\n",
       "          [ 2,  3]],\n",
       "\n",
       "         [[ 4,  5],\n",
       "          [ 6,  7]]],\n",
       "\n",
       "\n",
       "        [[[ 0, -1],\n",
       "          [-2, -3]],\n",
       "\n",
       "         [[-4, -5],\n",
       "          [-6, -7]]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that would be the input into MHSA, which would give back the same ouptput\n",
    "# now we want to unpack the MHSA back into the original shape\n",
    "# [batch_size x sequence_len x (query_key_dim * n_heads)]\n",
    "# if we do this right, the values should be exactly identical\n",
    "\n",
    "# Seperating heads\n",
    "# [batch_size x n_heads x sequence_len x query_key_dim]\n",
    "sample_val = sample_val.reshape(2, 2, 2, 2)\n",
    "sample_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "469b72fa-fe86-4e66-8c42-74f14eb36278",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0,  4],\n",
       "          [ 1,  5]],\n",
       "\n",
       "         [[ 2,  6],\n",
       "          [ 3,  7]]],\n",
       "\n",
       "\n",
       "        [[[ 0, -4],\n",
       "          [-1, -5]],\n",
       "\n",
       "         [[-2, -6],\n",
       "          [-3, -7]]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# moving the head dimension to the end\n",
    "# [batch_size x sequence_len x query_key_dim x n_heads]\n",
    "sample_val = sample_val.permute(0, 2, 3, 1)\n",
    "sample_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d2eafe7-3dad-4839-91bb-876779b06a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  4,  1,  5],\n",
       "         [ 2,  6,  3,  7]],\n",
       "\n",
       "        [[ 0, -4, -1, -5],\n",
       "         [-2, -6, -3, -7]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining the last dim to effectively concatinate the result of the heads\n",
    "# [batch_size x sequence_len x query_key_dim*n_heads]\n",
    "sample_val = sample_val.reshape(2, 2, -1)\n",
    "sample_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffa96317-0030-4c1e-8714-a2d2786ce597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6cff42f-c594-4afb-80a4-dddf53d42a19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the shapes at each step\n",
    "shapes = [\n",
    "    (2, 2, 4),  # Original shape\n",
    "    (2, 2, 2, 2),  # Split into heads\n",
    "    (2, 2, 2, 2),  # Move head dimension\n",
    "    (4, 2, 2),  # Merge batch and head dimensions\n",
    "    (2, 2, 2, 2),  # Separate heads again\n",
    "    (2, 2, 2, 2),  # Move head dimension to the end\n",
    "    (2, 2, 4)  # Combine last two dimensions\n",
    "]\n",
    "\n",
    "# Define the labels for each step\n",
    "labels = [\n",
    "    \"Original Shape\",#\\n[batch_size, sequence_len, query_key_dim * n_heads]\",\n",
    "    \"Split into Heads\",#\\n[batch_size, sequence_len, query_key_dim, n_heads]\",\n",
    "    \"Move Head Dimension\",#\\n[batch_size, n_heads, sequence_len, query_key_dim]\",\n",
    "    \"Merge Batch and Head Dimensions\",#\\n[batch_size * n_heads, sequence_len, query_key_dim]\",\n",
    "    \"Separate Heads Again\",#\\n[batch_size, n_heads, sequence_len, query_key_dim]\",\n",
    "    \"Move Head Dimension to the End\",#\\n[batch_size, sequence_len, query_key_dim, n_heads]\",\n",
    "    \"Combine Last Two Dimensions\"#\\n[batch_size, sequence_len, query_key_dim * n_heads]\"\n",
    "]\n",
    "\n",
    "# Create the diagram\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot each shape transformation\n",
    "for i, (shape, label) in enumerate(zip(shapes, labels)):\n",
    "    rect = plt.Rectangle((i * 2, 0), 1.5, 1, edgecolor='black', facecolor='lightblue')\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(i * 2 + 0.75, 0.5, str(shape), ha='center', va='center', fontsize=12)\n",
    "    ax.text(i * 2 + 0.75, -0.2, label, ha='center', va='center', fontsize=10)\n",
    "\n",
    "# Draw arrows between shapes\n",
    "for i in range(len(shapes) - 1):\n",
    "    ax.arrow(i * 2 + 1.5, 0.5, 0.5, 0, head_width=0.1, head_length=0.2, fc='black', ec='black')\n",
    "\n",
    "# Set plot limits and remove axes\n",
    "ax.set_xlim(-1, len(shapes) * 2)\n",
    "ax.set_ylim(-1, 2)\n",
    "ax.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.title(\"Shape Transformations in Multi-Head Self-Attention (MHSA) in BERT\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223fd21b-3ca9-4273-a887-842a594d78b0",
   "metadata": {},
   "source": [
    "### Building MHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3941f30d-c31e-43fd-826f-65b8a1905081",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define constants\n",
    "n_heads = 3\n",
    "query_key_dim = 64\n",
    "value_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "045353d4-1b7c-429c-b986-c4c4c2e9a7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        # Defining the linear layers to construct the query, key, value\n",
    "        self.W_Q = nn.Linear(d_model, query_key_dim * n_heads) # Projects input to [batch x sequence x (q/k_dim*num_heads)]\n",
    "        self.W_K = nn.Linear(d_model, query_key_dim * n_heads) # Projects input to [batch x sequence x (q/k_dim*num_heads)]\n",
    "        self.W_V = nn.Linear(d_model, value_dim * n_heads) # Projects input to [batch x sequence x (value_dim*num_heads)]\n",
    "        self.dot_prod_attn = ScaledDotProductAttention()   # Parameterless system to calculate attention\n",
    "        self.proj_back = nn.Linear(value_dim * n_heads, d_model) # Projects final output\n",
    "        \n",
    "    def forward(self, embedding):\n",
    "        # Pass embedding through dense networks\n",
    "        qs = self.W_Q(embedding) # [batch x sequence x (query_key_dim*num_heads)]\n",
    "        ks = self.W_K(embedding) # [batch x sequence x (query_key_dim*num_heads)]        \n",
    "        vs = self.W_V(embedding) # [batch x sequence x (value_dim*num_heads)]\n",
    "        \n",
    "        # dividing ot heads\n",
    "        # [batch_size, sequence_len, q/k/v_dim, n_heads]\n",
    "        qs = qs.view(batch_size, max_input_length, query_key_dim, n_heads)\n",
    "        ks = ks.view(batch_size, max_input_length, query_key_dim, n_heads)        \n",
    "        vs = vs.view(batch_size, max_input_length, value_dim, n_heads)\n",
    "        \n",
    "        # moving the head dimension next to the batch dimension\n",
    "        # [batch_size x n_heads x sequence_len x q/k/v_dim]\n",
    "        qs = qs.permute(0, 3, 1, 2)\n",
    "        ks = ks.permute(0, 3, 1, 2)        \n",
    "        vs = vs.permute(0, 3, 1, 2)\n",
    "        \n",
    "        # Combining batch and head dimension\n",
    "        # [batch_size*n_heads x sequence_len x q/k/v_dim]\n",
    "        qs = qs.reshape(-1, max_input_length, query_key_dim)\n",
    "        ks = ks.reshape(-1, max_input_length, query_key_dim)        \n",
    "        vs = vs.reshape(-1, max_input_length, value_dim)\n",
    "        \n",
    "        # Passing batches/heads of self attention through attn\n",
    "        # [batch_size*n_heads x sequence_len x q/k/v_dim]\n",
    "        head_results, _ = self.dot_prod_attn(qs, ks, vs)\n",
    "        \n",
    "        # Seperating heads\n",
    "        # [batch_size x n_heads x sequence_len x v_dim]\n",
    "        head_results = head_results.reshape(batch_size, n_heads, max_input_length, value_dim)\n",
    "        \n",
    "        # moving the head dimension to the end\n",
    "        # [batch_size x sequence_len x query_key_dim x n_heads]\n",
    "        head_results = head_results.permute(0, 2, 3, 1)\n",
    "        \n",
    "        # combinig the last dim to effectively concatinate the result of the heads\n",
    "        # [batch_size x sequence_len x query_key_dim*n_heads]\n",
    "        head_results = head_results.reshape(batch_size, max_input_length, -1)\n",
    "        \n",
    "        # Projecting result of head back into model dimension\n",
    "        return self.proj_back(head_results)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2aeafbcb-3add-4930-87c4-5f32a10b1dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embeddings shape: torch.Size([128, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "sample_embeddings = torch.tensor([[[1.1] * d_model] * max_input_length] * batch_size).to(device)\n",
    "print(f'Sample embeddings shape: {sample_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4ea7494e-0703-4398-93ea-d1d18aa0186b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape of MHSA: torch.Size([128, 64, 256])\n"
     ]
    }
   ],
   "source": [
    "sample = MultiHeadSelfAttention().to(device)\n",
    "output = sample(sample_embeddings)\n",
    "print(f'Output shape of MHSA: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e587342e-bd19-4436-bc4d-fa7d8160dd68",
   "metadata": {},
   "source": [
    "## Pointwise Feed Forward\n",
    "we’re expanding the vectors to four times their length with a neural network, applying a non-linear activation function, then compressing that data back into the original model dimension length "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49e850f7-8311-4045-a6ac-65d2dfcb2177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_ff = 4 * d_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "97efd2e6-6a53-4fed-9957-25c8ed83b29f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PointWiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PointWiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
    "        return self.fc2(torch.nn.functional.gelu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a64eb3-f365-4eb9-9b06-6df475712f4c",
   "metadata": {},
   "source": [
    "## The Encoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0dd2ff58-3a8f-486c-953f-e83ffb8b4406",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.mhsa = MultiHeadSelfAttention()\n",
    "        self.pwff = PointWiseFeedForwardNet()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mhsa_output = self.mhsa(x)\n",
    "        skip1 = mhsa_output + x\n",
    "        pwff_output = self.pwff(skip1)\n",
    "        skip2 = skip1 + pwff_output\n",
    "        return skip2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0958d00b-8e1e-4dfc-b9df-c22356f5f21d",
   "metadata": {},
   "source": [
    "## Building BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0331f7e0-5adc-4ea4-80f5-cf9dd6c9b575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5d9c15b-254b-49b4-bbaa-7ce9d356186a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        self.embedding = Embedding() # convert tokens into vector embeddings\n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock() for _ in range(n_layers)]) # Encoder blocks\n",
    "        # Decoding a word vector into token predictions\n",
    "        self.decoder = nn.Linear(d_model, tokenizer.vocab_size, bias=False)\n",
    "        # Converting first output token into a binary classification\n",
    "        self.classifier = nn.Linear(d_model, 1, bias = False)\n",
    "        \n",
    "    def forward(self, x, seg, masked_token_locations):\n",
    "        # x of shape [batch x seq_len x model_dim]\n",
    "        embeddings = self.embedding(x, seg)\n",
    "        x = embeddings\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # passing first token through classifier\n",
    "        clsf_logits = self.classifier(x[:, 0, :])\n",
    "        \n",
    "        # passing masked tokens through decoder\n",
    "        masked_token_embeddings = embeddings[masked_token_locations.bool()]\n",
    "        token_logits = self.decoder(masked_token_embeddings)\n",
    "        \n",
    "        return clsf_logits, token_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd799e-59cb-4fcb-8741-99ae2dd8667e",
   "metadata": {},
   "source": [
    "## Pretraining BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d348717-6dc9-4204-bf28-f172407e8feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0b3b2dec-9155-41a6-86f8-b27579752394",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = BERT().to(device)\n",
    "token_criterion = nn.CrossEntropyLoss() # Expect indices not one-hot vectors\n",
    "classification_criterion = nn.BCEWithLogitsLoss() # For logits directly\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7068616-684a-4a29-9434-6ee2fe4568e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "744it [09:35,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch 0 Completed\n",
      "average loss in epoch: 8.055456192262712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "744it [12:14,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch 1 Completed\n",
      "average loss in epoch: 7.694260349196773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "380it [15:51,  2.65s/it]"
     ]
    }
   ],
   "source": [
    "losses = [[]]\n",
    "\n",
    "for epoch in range(4):\n",
    "    for sequence_batch, location_batch, classtag_batch in tqdm(zip(sequence_tokens_batches, sentence_location_batches, is_positive_batches)):\n",
    "        # Zeroing out gradients from last iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Masking the tokens in the input sequence\n",
    "        masked_tokens, masked_token_locations = mask_batch(sequence_batch)\n",
    "        \n",
    "        # Generating class and masked token predictions\n",
    "        clsf_logits, token_logits = model(masked_tokens, location_batch, masked_token_locations)\n",
    "        \n",
    "        # Setting up the target for masked token prediction\n",
    "        masked_token_targets = sequence_batch[masked_token_locations.bool()]\n",
    "        \n",
    "        # Calculating loss for the next sentence classification\n",
    "        loss_clsf = classification_criterion(clsf_logits.squeeze(), classtag_batch.float())\n",
    "        \n",
    "        # Calculating the loss for masked language modeling\n",
    "        loss_mlm = token_criterion(token_logits, masked_token_targets)\n",
    "        \n",
    "        # Combining losses\n",
    "        loss = loss_clsf + loss_mlm\n",
    "        \n",
    "        losses[-1].append(float(loss))\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'=====Epoch {epoch} Completed')\n",
    "    print(f'average loss in epoch: {np.mean(losses[-1])}')\n",
    "    losses.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe8bf16-5d55-4da5-acc1-17e4ee75e488",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffc4bc7-972d-4756-baa0-a3cf61b94bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " # Loading dataset\n",
    "    \n",
    "fine_tune_ds = load_dataset('fancyzhx/amazon_polarity')\n",
    "\n",
    "for e in fine_tune_ds['train']:\n",
    "    print(e)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897100af-56ba-4122-a3b2-54ea7edb638f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Turning Amazon dataset to BERT friendly dataset\n",
    "\n",
    "def preprocess_data(data, max_num = 100000):\n",
    "    data_tokens = []\n",
    "    data_positional = []\n",
    "    data_targets = []\n",
    "    \n",
    "    # unpacking data\n",
    "    for i, elem in enumerate(data):\n",
    "        # Tokenize title and content\n",
    "        sentence1 = elem['title']\n",
    "        sentence2 = elem['content']\n",
    "        tokens = tokenizer([sentence1, sentence2])\n",
    "        sentence1_tokens = tokens['input_ids'][0]\n",
    "        sentence2_tokens = tokens['input_ids'][1]\n",
    "        \n",
    "        # Trimming down the tokens\n",
    "        if len(sentence1_tokens) + len(sentence2_tokens) > max_input_length:\n",
    "            sentence1_tokens = [101] + sentence1_tokens[-int(max_input_length / 2) + 1:]\n",
    "            sentence2_tokens = sentence2_tokens[:int(max_input_length/2) -1] + [102]\n",
    "\n",
    "        # Creating Sentence tokens\n",
    "        sentence_tokens = [0] * len(sentence1_tokens) + [1] * len(sentence2_tokens)\n",
    "        \n",
    "        # Combining and padding\n",
    "        pad_num = max_input_length - (len(sentence1_tokens) + len(sentence2_tokens))\n",
    "        sequence_tokens = sentence1_tokens + sentence2_tokens + [0] * pad_num\n",
    "        sentence_location_tokens = sentence_tokens + [1] * pad_num\n",
    "        \n",
    "        if not (len(sequence_tokens) == max_input_length and len(sentence_location_tokens) == max_input_length):\n",
    "            print(len(sequence_tokens), len(sentence_location_tokens))\n",
    "            print(sentence1_tokens, sentence2_tokens)\n",
    "        \n",
    "        # Adding to the batch\n",
    "        data_tokens.append(sequence_tokens)\n",
    "        data_positional.append(sentence_location_tokens)\n",
    "        data_targets.append(elem['label'])\n",
    "\n",
    "        if i > max_num: break\n",
    "    \n",
    "    return torch.tensor(data_positional), torch.tensor(data_tokens), torch.tensor(data_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93026b0-0600-4c39-9a77-67f99240a73f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# processing data into modeling data\n",
    "train_pos, train_tok, train_tar = preprocess_data(fine_tune_ds['train'])\n",
    "test_pos, test_tok, test_tar = preprocess_data(fine_tune_ds['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26475187-e5fd-4600-87b1-ec3909b25a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Moving training to device\n",
    "train_pos = train_pos.to(device)\n",
    "train_tok = train_tok.to(device)\n",
    "train_tar = train_tar.to(device)\n",
    "\n",
    "# Moving testing to device\n",
    "test_pos = test_pos.to(device)\n",
    "test_tok = test_tok.to(device)\n",
    "test_tar = test_tar.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133cb77b-00d8-49e5-a70b-1829f819ddf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replacing the classifier head with new head\n",
    "# Since new problem requires us to classify the review as positive or negative\n",
    "\n",
    "model.classifier = nn.Linear(d_model, 1, bias=False).to(device)\n",
    "\n",
    "# Resetting the optimizer to access the parameter of new head\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74882b55-7af7-446d-8040-c0f00351372c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [13:39<00:01,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Epoch 3 Completed =====\n",
      "average loss in epoch: 0.691419141126198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [13:35<00:01,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Epoch 4 Completed =====\n",
      "average loss in epoch: 0.690081260909497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ft_losses = [[]*1]\n",
    "\n",
    "for epoch in range(5):\n",
    "    for i in tqdm(range(0, train_pos.shape[0], batch_size)):\n",
    "        \n",
    "        if i + batch_size >= train_pos.shape[0]:\n",
    "            break\n",
    "        \n",
    "        # Get batch\n",
    "        train_pos_batch = train_pos[i:i+batch_size]\n",
    "        train_tok_batch = train_tok[i:i+batch_size]\n",
    "        train_tar_batch = train_tar[i:i+batch_size]\n",
    "        \n",
    "        # Zeroing the gradients from last iteration\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Masking the tokens in the input sequence\n",
    "        masked_tokens, masked_token_locations = mask_batch(train_tok_batch)\n",
    "        \n",
    "        # Generating class and masked token prediction\n",
    "        clsf_logits, token_logits = model(train_tok_batch, train_pos_batch, masked_token_locations)\n",
    "        \n",
    "        # Setting up target for masked token prediction\n",
    "        masked_token_targets = sequence_batch[masked_token_locations.bool()]\n",
    "        \n",
    "        # Calculating loss for next sentence classification\n",
    "        loss_clsf = classification_criterion(clsf_logits.squeeze(), train_tar_batch.float())\n",
    "        \n",
    "        loss = loss_clsf\n",
    "        ft_losses[-1].append(float(loss))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'===== Epoch {epoch} Completed =====')\n",
    "    print(f'average loss in epoch: {np.mean(ft_losses[-1])}')\n",
    "    losses.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fa71d28c-e015-47c1-848d-b9eb882a80fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 781/782 [01:18<00:00,  9.95it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.515044814340589)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_correct = []\n",
    "predicted_class = []\n",
    "original_class = []\n",
    "\n",
    "for i in tqdm(range(0, test_pos.shape[0], batch_size)):\n",
    "    if i+batch_size >= test_pos.shape[0]:\n",
    "        break\n",
    "    \n",
    "    # Getting batch\n",
    "    test_pos_batch = test_pos[i:i+batch_size]\n",
    "    test_tok_batch = test_tok[i:i+batch_size]    \n",
    "    test_tar_batch = test_tar[i:i+batch_size]\n",
    "    \n",
    "    # Making prediction\n",
    "    clsf_logits, _ = model(test_tok_batch, test_pos_batch, torch.zeros(test_pos_batch.shape))\n",
    "    \n",
    "    # Converting logits to probability\n",
    "    res = torch.sigmoid(clsf_logits).round().squeeze()\n",
    "    \n",
    "    # Keep track of the original class\n",
    "    original_class.extend(np.array(test_tar_batch.to('cpu')))\n",
    "    is_correct.extend(np.array((res == test_tar_batch).to('cpu')))\n",
    "    predicted_class.extend(np.array(res.detach().to('cpu')))\n",
    "    \n",
    "# Accuracy\n",
    "sum(list(is_correct))/len(is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfdb610-40e9-474f-9608-16db901e203f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-default:Python",
   "language": "python",
   "name": "conda-env-.conda-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
